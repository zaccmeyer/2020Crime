{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crime in LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_data = pd.read_csv('Crime_Data_from_2020_to_Present.csv') #load in data\n",
    "\n",
    "crime_data = crime_data.drop(columns=['Vict Descent','Status','Status Desc']) #drop irrelevant columns\n",
    "\n",
    "crime_data.dropna(inplace=True) #drop nan data and remove unwanted columns\n",
    "\n",
    "#make sure there is a valid location listed\n",
    "crime_data = crime_data[crime_data['LON'] != 0]\n",
    "crime_data = crime_data[crime_data['LAT'] != 0]\n",
    "\n",
    "# DROP CRIMES WITH ONLY A FEW INCIDENTS\n",
    "X = crime_data.drop(columns=['Crm Cd 1', 'Crm Cd 2', 'Crm Cd 3', 'Crm Cd 4', 'Crm Cd']) #drop all extra crime codes\n",
    "y = crime_data['Crm Cd']   #crime code column\n",
    "\n",
    "num_incidents = 1000  #minimum number of incidents required to keep crime\n",
    "crimes = []\n",
    "for i in set(y):\n",
    "    if len(crime_data[crime_data['Crm Cd']==i])>num_incidents:\n",
    "        crimes.append(i)\n",
    "\n",
    "#remove other crime codes in data\n",
    "crime_data = crime_data[crime_data['Crm Cd'].isin(crimes)]\n",
    "\n",
    "df = pd.get_dummies(crime_data, columns = ['TIME OCC', 'LOCATION', 'Cross Street', 'Vict Sex',]) #one hot encode categorical data\n",
    "df['Vict Sex'] = df['Vict Sex_H'] + 2*df['Vict Sex_M'] + 3*df['Vict Sex_X'] #recombine victom sex columns\n",
    "\n",
    "#convert time indices\n",
    "df['DATE OCC'] = pd.to_datetime(df['DATE OCC'], format='%m/%d/%Y %I:%M:%S %p')\n",
    "df['year'] = df['DATE OCC'].dt.year\n",
    "df['month'] = df['DATE OCC'].dt.month\n",
    "df['day'] = df['DATE OCC'].dt.day\n",
    "df['hour'] = df['DATE OCC'].dt.hour\n",
    "df['day_of_week'] = df['DATE OCC'].dt.dayofweek\n",
    "\n",
    "#check types of each column and drop columns with unwanted type\n",
    "columns_to_drop = []\n",
    "for i in df.columns:\n",
    "    \n",
    "    if df[i].dtype!='float64' and df[i].dtype!= 'uint8' and df[i].dtype != 'int64':\n",
    "        columns_to_drop.append(i)\n",
    "        \n",
    "    #drop other crime code columns\n",
    "    if re.search('Crm Cd*', i):\n",
    "        columns_to_drop.append(i)\n",
    "        \n",
    "#drop other unwanted columns\n",
    "columns_to_drop.append('DR_NO')\n",
    "columns_to_drop.append('Part 1-2')\n",
    "new_df = df.drop(columns = columns_to_drop)   #drop columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmeans Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load real data\n",
    "station_loc = pd.read_csv('Sheriff_and_Police_Stations.csv')\n",
    "\n",
    "#get data for Los Angeles\n",
    "station_loc1 = station_loc[station_loc['city']=='Los Angeles']   \n",
    "real_loc = station_loc1[['latitude','longitude']]\n",
    "\n",
    "class KMeans:\n",
    "    \"\"\"Basic k-means clustering class.\"\"\"\n",
    "    def __init__(self, n_clusters=8, max_iter=100, tol=1e-5, normalize=False, p=2):\n",
    "        \"\"\"Store clustering algorithm parameters.\n",
    "        \n",
    "        Parameters:\n",
    "            n_clusters (int): How many clusters to compute.\n",
    "            max_iter (int): The maximum number of iterations to compute.\n",
    "            tol (float): The convergence tolerance.\n",
    "        \"\"\"\n",
    "        self.n_clusters = n_clusters #initialize everything\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.p = p\n",
    "        self.normalize = normalize\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Compute the cluster centers from random initial conditions.\n",
    "        \n",
    "        Parameters:\n",
    "            X ((n_samples, n_classes) ndarray): the data to be clustered.\n",
    "        \"\"\"\n",
    "        \n",
    "        #set our centers and then normalize if we need to \n",
    "        self.centers = X[np.random.choice(X.shape[0],self.n_clusters,replace=False)]\n",
    "        \n",
    "        if self.normalize == True:\n",
    "            self.centers = np.reshape(self.centers/np.linalg.norm(self.centers,axis=1),(-1,1))\n",
    "            \n",
    "        #iterate thorugh max iter and create the label and new center\n",
    "        for i in range(0,self.max_iter): \n",
    "            \n",
    "                label = np.argmin(np.linalg.norm(X[:,np.newaxis]-self.centers,ord=self.p,axis=2),axis=1)\n",
    "                new_c = np.array([X[label==z].mean(axis=0) for z in range(self.n_clusters)])\n",
    "                \n",
    "                if np.linalg.norm(new_c-self.centers,ord=self.p) <self.tol: #if error is less than tol break\n",
    "                     break\n",
    "                        \n",
    "                self.centers = new_c #set the new center and normalize \n",
    "                if self.normalize == True:\n",
    "                    \n",
    "                    self.centers = np.reshape(self.centers/np.linalg.norm(self.centers,axis=1),(-1,1))\n",
    "                    \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Classify each entry of X based on which cluster center it belongs to.\n",
    "\n",
    "        Parameters:\n",
    "            X ((n_samples, n_classes) ndarray): the data to be clustered.\n",
    "        \n",
    "        Returns:\n",
    "            ((n_samples) ndarray): Integer labels from 0 to n_clusters for each entry of X.\n",
    "        \"\"\"\n",
    "        \n",
    "        #make our distance and return the argmin of it\n",
    "        my_dist = np.linalg.norm(X[:,np.newaxis]-self.centers,ord=self.p,axis=2)\n",
    "        \n",
    "        return np.argmin(my_dist,axis=1)\n",
    "    \n",
    "    def fit_predict(self, X):\n",
    "        \"\"\"Fit to the data and return the resulting labels.\n",
    "\n",
    "        Parameters:\n",
    "            X ((n_samples, n_classes) ndarray): the data to be clustered.\n",
    "        \"\"\"\n",
    "        return self.fit(X).predict(X)\n",
    "    \n",
    "    def plot(self, X, y):\n",
    "        \"\"\"Plot each of the data points, colored by cluster.\n",
    "        Plot each of the cluster centers using a different marker.\n",
    "\n",
    "        Parameters:\n",
    "            X ((n_samples, n_classes) ndarray): the data being clustered.\n",
    "            y ((n_samples) ndarray): the labels for each of the samples.\n",
    "        \"\"\"\n",
    "        \n",
    "        #plot the points and then the centers\n",
    "        plt.scatter(X[:,0],X[:,1],c=y)\n",
    "        plt.scatter(self.centers[:,0],self.centers[:,1],marker='+',color='black',label='Optimal Location')\n",
    "        plt.scatter(real_loc['longitude'],real_loc['latitude'],marker='+',color='red',label='Real Location')\n",
    "        \n",
    "        #initialize plot attributes\n",
    "        plt.legend()\n",
    "        plt.xlabel('Longitude')\n",
    "        plt.ylabel('Latitude')\n",
    "        plt.title('Police Station Locations in LA County')\n",
    "        plt.show()\n",
    "\n",
    "#run kmeans algorithm on our data\n",
    "location = new_df[['LON','LAT']]   #locations from our data and drop 0s from latitude and longitude\n",
    "new_loc = location[~(location == 0).all(axis=1)]\n",
    "new_data = new_loc[['LON','LAT']].values\n",
    "\n",
    "for x in [1,2,np.inf]: #iterate through our different norms \n",
    "    km = KMeans(n_clusters=17,p=x) #initialize our class, fit it and then predict and plot it \n",
    "    km.fit(new_data)\n",
    "    y = km.predict(new_data)\n",
    "    km.plot(new_data,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define your training and test data\n",
    "X = new_df\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['Crm Cd'])\n",
    "X_train,X_test,y_train, y_test = train_test_split(X,y, test_size = 0.3)\n",
    "\n",
    "#define a Parameter Grid\n",
    "rf = RandomForestClassifier()\n",
    "param_grid = {'n_estimators': [25,50,100], \"criterion\": ['gini','entropy'], \"max_features\": \n",
    "              [None,'sqrt','log2'], 'max_depth': [5,10]}\n",
    "\n",
    "#Perform a Grid search with 3-fold cross validation\n",
    "rf_gs = GridSearchCV(rf,param_grid,cv = 3, n_jobs = -1)\n",
    "rf_gs.fit(X_train, y_train)\n",
    "\n",
    "#display the best parameters and your score\n",
    "print(f'Best Parameters: {rf_gs.best_params_}')\n",
    "print(f'Best Score: {rf_gs.best_score_}')\n",
    "\n",
    "#DEFINE RANDOM FOREST WITH OPTIMAL PARAMETERS\n",
    "#provide labels to each crime code from the cleaned data\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['Crm Cd'])\n",
    "rf = RandomForestClassifier(n_estimators=100,criterion='gini', max_depth=10, max_features=None)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "#get your predictions, accuracy and f1 score\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy_s = accuracy_score(y_test, y_pred)\n",
    "f1_score(y_test, y_pred, average = 'micro')\n",
    "\n",
    "#get the Optimal Features based off of feature importance\n",
    "sel = SelectFromModel(RandomForestClassifier(criterion = 'gini', max_depth = 10, n_estimators = 100))\n",
    "sel.fit(X_train, y_train)\n",
    "\n",
    "#select the features to retrain the model on\n",
    "X_selected = sel.fit_transform(X_train, y_train)\n",
    "X_selected = X_selected.astype(int)\n",
    "sel.get_support()\n",
    "selected_feat = X_train.columns[(sel.get_support())]\n",
    "\n",
    "X = X_train[selected_feat]   #use selected features\n",
    "\n",
    "#construct the randomforest classifier\n",
    "rf = RandomForestClassifier(n_estimators=200, criterion='gini', max_depth=10, max_features=None) \n",
    "rf.fit(X, y_train)\n",
    "\n",
    "#get predictions and accuracy\n",
    "y_pred = rf.predict(X_test[selected_feat])\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "#display the classification report for each crime code\n",
    "label_names = list(map(str, df['Crm Cd'].unique()))\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "#Construct your crime data from nominal data\n",
    "y = le.fit_transform(df['Crm Cd'])\n",
    "X_train,X_test,y_train, y_test = train_test_split(X,y, test_size = 0.3)\n",
    "\n",
    "#initialize classifier and set parameters\n",
    "rf = GradientBoostingClassifier()\n",
    "param_grid = {'n_estimators': [25,50,100], \"loss\": ['log_loss','exponential'], \"max_features\": [None,'sqrt','log2'], 'max_depth': [5,10], 'min_samples_leaf': [1,4,8]}\n",
    "\n",
    "#run the grid search\n",
    "rf_gs = GridSearchCV(rf,param_grid,cv = 3, n_jobs = -1)\n",
    "rf_gs.fit(X_train, y_train)\n",
    "\n",
    "#display the best parameters and your score\n",
    "print(f'Best Parameters: {rf_gs.best_params_}')\n",
    "print(f'Best Score: {rf_gs.best_score_}')\n",
    "\n",
    "#DEFINE GRADIENT BOOSTED FOREST WITH OPTIMAL PARAMETERS\n",
    "#provide labels to each crime code from the cleaned data\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['Crm Cd'])\n",
    "rf = RandomForestClassifier(n_estimators=100,criterion='gini', max_depth=10, max_features=None)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "#get your predictions, accuracy and f1 score\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy_s = accuracy_score(y_test, y_pred)\n",
    "f1_score(y_test, y_pred, average = 'micro')\n",
    "\n",
    "#get the Optimal Features based off of feature importance\n",
    "sel = SelectFromModel(RandomForestClassifier(criterion = 'gini', max_depth = 10, n_estimators = 100))\n",
    "sel.fit(X_train, y_train)\n",
    "\n",
    "#select the features to retrain the model on\n",
    "X_selected = sel.fit_transform(X_train, y_train)\n",
    "X_selected = X_selected.astype(int)\n",
    "sel.get_support()\n",
    "selected_feat = X_train.columns[(sel.get_support())]\n",
    "\n",
    "X = X_train[selected_feat]   #use selected features\n",
    "\n",
    "#build classifier\n",
    "rf = RandomForestClassifier(n_estimators=200, criterion='gini', max_depth=10, max_features=None) \n",
    "rf.fit(X, y_train)\n",
    "\n",
    "#get predictions and accuracy\n",
    "y_pred = rf.predict(X_test[selected_feat])\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "#build a classification report\n",
    "label_names = list(map(str, df['Crm Cd'].unique()))\n",
    "print(classification_report(y_test, y_pred, target_names=label_names, zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Logistic Regression Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "#get crime data X and labels y\n",
    "y = le.fit_transform(crime_data['Crm Cd'])\n",
    "\n",
    "#split test data and initialize model\n",
    "X_train,X_test,y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state=3)\n",
    "\n",
    "#initialize logistic regression model\n",
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', C=1, max_iter=500)   \n",
    "\n",
    "#train and run test data\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "#get accuracy score\n",
    "accuracy = logreg.score(X_test, y_test)\n",
    "print(f'Accuracy of the Logistic Regression Model: {accuracy}')\n",
    "\n",
    "#perform PCA\n",
    "pca=PCA(n_components=2)\n",
    "X_test=pca.fit_transform(X_test)\n",
    "\n",
    "#display classification with the two best principal components\n",
    "plt.scatter(X_test[:,0], X_test[:,1], marker='.', c=y_test)   #plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Jeddy Bennett"
   },
   {
    "name": "Mckayla Davis"
   },
   {
    "name": "Zac Meyer"
   },
   {
    "name": "Mckay Shields"
   },
   {
    "name": "Lydia Tolman"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "title": "Crime Classification Code",
  "vscode": {
   "interpreter": {
    "hash": "f9667e94c5242b6e179d4931e51f0ea8382a201d07ce0883b2e989376c502410"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
